"""
train.py

ä¸»è®­ç»ƒè„šæœ¬ - æ•´åˆæ‰€æœ‰æ¨¡å—ï¼Œå®ç°å®Œæ•´çš„è¿›åŒ–è®­ç»ƒæµç¨‹
"""

from dataclasses import dataclass, field, asdict
from typing import Optional, Dict, Any, List
import json
import os
import shutil
from pathlib import Path

# 4é˜¶æ®µè®­ç»ƒç›¸å…³å¯¼å…¥
from stage_config import (
    TrainingStage, StageConfig,
    create_stage_configs, create_quick_test_configs,
    calculate_win_rate_with_ci
)
from hall_of_fame import HallOfFame

from _import_bootstrap import TORCH_AVAILABLE, NUMPY_AVAILABLE

if not TORCH_AVAILABLE:
    raise RuntimeError("PyTorch is required for training. Install with: pip install torch")

import torch


# ============================================================
# é…ç½®ç®¡ç†
# ============================================================

@dataclass
class TrainingConfig:
    """è®­ç»ƒé…ç½®"""

    # ç§ç¾¤å‚æ•°
    population_size: int = 8
    elite_size: int = 2
    tournament_size: int = 3

    # é—ä¼ å‚æ•°
    crossover_alpha: float = 0.5
    mutation_rate: float = 0.1
    initial_temperature: float = 1.0
    min_temperature: float = 0.1
    cooling_rate: float = 0.99  # æ”¾ç¼“é€€ç«é€Ÿåº¦ï¼ˆåŸ0.95è¿‡å¿«ï¼‰

    # è®­ç»ƒå‚æ•°
    num_generations: int = 200   # å¢åŠ åˆ°200ä»£ï¼ˆåŸ50ä»£ï¼Œæ”¯æŒ100000åœºå¯¹æˆ˜ï¼‰
    max_game_steps: int = 500    # ä¿®å¤: 1000 -> 500 (2:30é™åˆ¶ï¼Œæ¯æ­¥0.3ç§’)
    action_temperature: float = 1.0

    # å¯¹æŠ—è®­ç»ƒå‚æ•°
    round_robin_until: int = 20  # å»¶é•¿å¾ªç¯èµ›é˜¶æ®µï¼ˆåŸ10ä»£ï¼‰
    tournament_games: int = 8    # å¢åŠ å¯¹å±€æ•°é‡ï¼ˆåŸ4åœºï¼‰
    num_workers: int = 4

    # æ¨¡å‹å‚æ•°
    d_model: int = 128
    num_layers: int = 2
    nhead: int = 4
    dim_feedforward: int = 256
    dropout: float = 0.1

    # æ£€æŸ¥ç‚¹å‚æ•°
    checkpoint_dir: str = "checkpoints"
    save_every: int = 5
    keep_best_n: int = 3

    # æ—¥å¿—å‚æ•°
    log_dir: str = "logs"
    log_every: int = 1

    # éšæœºç§å­
    seed: Optional[int] = None

    # å®éªŒåç§°
    experiment_name: str = "ctf_evolution"


def load_config(config_path: Optional[str] = None) -> TrainingConfig:
    """
    åŠ è½½è®­ç»ƒé…ç½®

    Args:
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆJSONæ ¼å¼ï¼‰

    Returns:
        TrainingConfigå¯¹è±¡
    """
    if config_path is None:
        return TrainingConfig()

    with open(config_path, 'r') as f:
        config_dict = json.load(f)

    return TrainingConfig(**config_dict)


def save_config(config: TrainingConfig, save_path: str) -> None:
    """ä¿å­˜é…ç½®åˆ°JSONæ–‡ä»¶"""
    config_dict = asdict(config)

    with open(save_path, 'w') as f:
        json.dump(config_dict, f, indent=2)


# ============================================================
# æ£€æŸ¥ç‚¹ç®¡ç†
# ============================================================

class CheckpointManager:
    """æ£€æŸ¥ç‚¹ç®¡ç†å™¨"""

    def __init__(
        self,
        checkpoint_dir: str,
        keep_best_n: int = 3,
        experiment_name: str = "experiment"
    ):
        """
        Args:
            checkpoint_dir: æ£€æŸ¥ç‚¹ä¿å­˜ç›®å½•
            keep_best_n: ä¿ç•™æœ€ä½³çš„Nä¸ªæ£€æŸ¥ç‚¹
            experiment_name: å®éªŒåç§°
        """
        self.checkpoint_dir = Path(checkpoint_dir) / experiment_name
        self.checkpoint_dir.mkdir(parents=True, exist_ok=True)
        self.keep_best_n = keep_best_n
        self.best_checkpoints = []  # [(fitness, path), ...]

    def save_checkpoint(
        self,
        generation: int,
        population: 'Population',
        temperature: float,
        stats: Dict[str, Any],
        is_best: bool = False
    ) -> str:
        """
        ä¿å­˜æ£€æŸ¥ç‚¹

        Args:
            generation: å½“å‰ä¸–ä»£
            population: ç§ç¾¤å¯¹è±¡
            temperature: å½“å‰æ¸©åº¦
            stats: ç»Ÿè®¡ä¿¡æ¯
            is_best: æ˜¯å¦ä¸ºæœ€ä½³æ£€æŸ¥ç‚¹

        Returns:
            æ£€æŸ¥ç‚¹æ–‡ä»¶è·¯å¾„
        """
        # ç”Ÿæˆæ–‡ä»¶å
        if is_best:
            filename = f"best_gen_{generation}"
        else:
            filename = f"checkpoint_gen_{generation}"

        checkpoint_dir = self.checkpoint_dir / filename
        checkpoint_dir.mkdir(parents=True, exist_ok=True)

        # ä¿å­˜ç§ç¾¤
        population.save_population(str(checkpoint_dir / "population"))

        # ä¿å­˜æ£€æŸ¥ç‚¹å…ƒæ•°æ®
        checkpoint_meta = {
            'generation': generation,
            'temperature': temperature,
            'stats': stats,
            'best_fitness': stats['best_fitness']
        }

        meta_path = checkpoint_dir / "checkpoint_meta.json"
        with open(meta_path, 'w') as f:
            json.dump(checkpoint_meta, f, indent=2)

        print(f"âœ“ æ£€æŸ¥ç‚¹å·²ä¿å­˜: {checkpoint_dir}")

        # æ›´æ–°æœ€ä½³æ£€æŸ¥ç‚¹åˆ—è¡¨
        if is_best:
            self._update_best_checkpoints(stats['best_fitness'], checkpoint_dir)

        return str(checkpoint_dir)

    def _update_best_checkpoints(self, fitness: float, filepath: Path) -> None:
        """æ›´æ–°æœ€ä½³æ£€æŸ¥ç‚¹åˆ—è¡¨"""
        self.best_checkpoints.append((fitness, filepath))
        self.best_checkpoints.sort(key=lambda x: x[0], reverse=True)

        # åˆ é™¤å¤šä½™çš„æ£€æŸ¥ç‚¹
        if len(self.best_checkpoints) > self.keep_best_n:
            _, old_path = self.best_checkpoints.pop()
            if old_path.exists():
                # FIX: Use shutil.rmtree() for directories instead of unlink()
                try:
                    shutil.rmtree(old_path)
                    print(f"åˆ é™¤æ—§æ£€æŸ¥ç‚¹: {old_path}")
                except Exception as e:
                    print(f"è­¦å‘Š: æ— æ³•åˆ é™¤æ£€æŸ¥ç‚¹ {old_path}: {e}")

    def load_checkpoint(self, checkpoint_path: str) -> Dict[str, Any]:
        """åŠ è½½æ£€æŸ¥ç‚¹"""
        checkpoint_dir = Path(checkpoint_path)

        # åŠ è½½å…ƒæ•°æ®
        meta_path = checkpoint_dir / "checkpoint_meta.json"
        with open(meta_path, 'r') as f:
            checkpoint_meta = json.load(f)

        print(f"âœ“ æ£€æŸ¥ç‚¹å·²åŠ è½½: {checkpoint_path}")
        return checkpoint_meta

    def get_latest_checkpoint(self) -> Optional[str]:
        """è·å–æœ€æ–°çš„æ£€æŸ¥ç‚¹è·¯å¾„"""
        checkpoints = list(self.checkpoint_dir.glob("checkpoint_gen_*"))
        if not checkpoints:
            return None

        latest = max(checkpoints, key=lambda p: p.stat().st_mtime)
        return str(latest)


# ============================================================
# æ—¥å¿—ç³»ç»Ÿ
# ============================================================

import csv
import time
from datetime import datetime


class TrainingLogger:
    """è®­ç»ƒæ—¥å¿—è®°å½•å™¨"""

    def __init__(self, log_dir: str, experiment_name: str):
        """
        Args:
            log_dir: æ—¥å¿—ä¿å­˜ç›®å½•
            experiment_name: å®éªŒåç§°
        """
        self.log_dir = Path(log_dir) / experiment_name
        self.log_dir.mkdir(parents=True, exist_ok=True)

        # åˆ›å»ºCSVæ—¥å¿—æ–‡ä»¶
        self.csv_path = self.log_dir / "training_log.csv"
        self.csv_file = open(self.csv_path, 'w', newline='')
        self.csv_writer = csv.writer(self.csv_file)

        # å†™å…¥è¡¨å¤´
        self.csv_writer.writerow([
            'generation', 'timestamp', 'temperature',
            'num_games', 'avg_steps', 'avg_duration_ms',
            'best_fitness', 'avg_fitness', 'worst_fitness',
            'l_wins', 'r_wins', 'draws', 'draw_rate',
            'avg_flags_captured', 'sparse_enabled'
        ])

        # åˆ›å»ºæ–‡æœ¬æ—¥å¿—æ–‡ä»¶
        self.txt_path = self.log_dir / "training.log"
        self.txt_file = open(self.txt_path, 'w')

        self.start_time = time.time()

    def log_generation(
        self,
        generation: int,
        temperature: float,
        stats: Dict[str, Any]
    ) -> None:
        """è®°å½•ä¸–ä»£ä¿¡æ¯"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        # è®¡ç®—å¹³å±€ç‡
        total_games = stats['num_games']
        draw_rate = stats['draws'] / total_games if total_games > 0 else 0.0

        # å†™å…¥CSV
        self.csv_writer.writerow([
            generation,
            timestamp,
            f"{temperature:.4f}",
            stats['num_games'],
            f"{stats['avg_steps']:.1f}",
            f"{stats['avg_duration_ms']:.1f}",
            f"{stats['best_fitness']:.2f}",
            f"{stats['avg_fitness']:.2f}",
            f"{stats['worst_fitness']:.2f}",
            stats['l_wins'],
            stats['r_wins'],
            stats['draws'],
            f"{draw_rate:.2%}",
            f"{stats.get('avg_flags_captured', 0):.2f}",
            stats.get('sparse_enabled', False)
        ])
        self.csv_file.flush()

        # å†™å…¥æ–‡æœ¬æ—¥å¿—
        elapsed = time.time() - self.start_time
        log_msg = (
            f"[ä¸–ä»£ {generation:3d}] "
            f"æ¸©åº¦={temperature:.3f} | "
            f"å¯¹å±€={stats['num_games']:3d} "
            f"(å¹³å‡{stats['avg_steps']:.0f}æ­¥/{stats['avg_duration_ms']/1000:.1f}ç§’) | "
            f"é€‚åº”åº¦: {stats['best_fitness']:6.2f} / "
            f"{stats['avg_fitness']:6.2f} / "
            f"{stats['worst_fitness']:6.2f} | "
            f"èƒœåœº: L={stats['l_wins']:3d} R={stats['r_wins']:3d} "
            f"å¹³={stats['draws']:2d} ({draw_rate:.0%}) | "
            f"ä¸–ä»£è®­ç»ƒæ—¶é•¿: {elapsed:.1f}ç§’"
        )

        print(log_msg)
        self.txt_file.write(log_msg + '\n')
        self.txt_file.flush()

    def log_message(self, message: str) -> None:
        """è®°å½•è‡ªå®šä¹‰æ¶ˆæ¯"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_msg = f"[{timestamp}] {message}"
        print(log_msg)
        self.txt_file.write(log_msg + '\n')
        self.txt_file.flush()

    def close(self) -> None:
        """å…³é—­æ—¥å¿—æ–‡ä»¶"""
        self.csv_file.close()
        self.txt_file.close()


# ============================================================
# ä¸»è®­ç»ƒå¾ªç¯
# ============================================================

import random
import numpy as np


class EvolutionaryTrainer:
    """è¿›åŒ–è®­ç»ƒå™¨ - æ•´åˆæ‰€æœ‰æ¨¡å—"""

    def __init__(self, config: TrainingConfig):
        """
        Args:
            config: è®­ç»ƒé…ç½®
        """
        self.config = config

        # è®¾ç½®éšæœºç§å­
        if config.seed is not None:
            self._set_seed(config.seed)

        # åˆå§‹åŒ–ç»„ä»¶
        self.logger = TrainingLogger(config.log_dir, config.experiment_name)
        self.checkpoint_manager = CheckpointManager(
            config.checkpoint_dir,
            config.keep_best_n,
            config.experiment_name
        )

        # åˆ›å»ºç§ç¾¤
        from population import Population, PopulationConfig
        from transformer_model import CTFTransformerConfig

        pop_config = PopulationConfig(
            population_size=config.population_size,
            elite_size=config.elite_size,
            tournament_size=config.tournament_size
        )

        model_config = CTFTransformerConfig(
            d_model=config.d_model,
            num_layers=config.num_layers,
            nhead=config.nhead,
            dim_feedforward=config.dim_feedforward,
            dropout=config.dropout
        )

        self.population = Population(pop_config)
        self.population.initialize_random(model_config)
        self.logger.log_message(f"ç§ç¾¤å·²åˆ›å»º: {config.population_size} ä¸ªä½“")

        # åˆ›å»ºå¥–åŠ±ç³»ç»Ÿ
        from reward_system import AdaptiveRewardSystem
        self.reward_system = AdaptiveRewardSystem()

        # åˆ›å»ºå¯¹æŠ—è®­ç»ƒå™¨
        from adversarial_trainer import AdversarialTrainer, AdaptiveMatchupStrategy

        matchup_strategy = AdaptiveMatchupStrategy(
            round_robin_until=config.round_robin_until,
            tournament_games=config.tournament_games
        )

        self.adversarial_trainer = AdversarialTrainer(
            matchup_strategy=matchup_strategy,
            reward_system=self.reward_system,
            num_workers=config.num_workers,
            max_steps=config.max_game_steps,
            temperature=config.action_temperature
        )

        # é—ä¼ ç®—æ³•å‚æ•°
        from genetic_ops import AnnealingScheduler, AnnealingConfig

        annealing_config = AnnealingConfig(
            initial_temperature=config.initial_temperature,
            min_temperature=config.min_temperature,
            cooling_rate=config.cooling_rate
        )
        self.annealing = AnnealingScheduler(annealing_config)

        self.current_generation = 0
        self.best_fitness_ever = float('-inf')

    def _set_seed(self, seed: int) -> None:
        """è®¾ç½®éšæœºç§å­"""
        random.seed(seed)
        np.random.seed(seed)
        torch.manual_seed(seed)
        if torch.cuda.is_available():
            torch.cuda.manual_seed_all(seed)

    def train(self, resume_from: Optional[str] = None) -> None:
        """
        æ‰§è¡Œå®Œæ•´è®­ç»ƒæµç¨‹

        Args:
            resume_from: æ£€æŸ¥ç‚¹è·¯å¾„ï¼ˆå¯é€‰ï¼Œç”¨äºæ¢å¤è®­ç»ƒï¼‰
        """
        # æ¢å¤è®­ç»ƒ
        if resume_from:
            self._resume_from_checkpoint(resume_from)

        self.logger.log_message("=" * 60)
        self.logger.log_message("å¼€å§‹è¿›åŒ–è®­ç»ƒ")
        self.logger.log_message("=" * 60)
        self.logger.log_message(f"é…ç½®: population_size={self.config.population_size}, "
                                f"generations={self.config.num_generations}")

        # ä¸»å¾ªç¯
        for generation in range(self.current_generation, self.config.num_generations):
            self.current_generation = generation

            # è·å–å½“å‰æ¸©åº¦
            temperature = self.annealing.get_temperature(generation)

            self.logger.log_message(f"\n{'='*60}")
            self.logger.log_message(f"ä¸–ä»£ {generation}/{self.config.num_generations}")
            self.logger.log_message(f"æ¸©åº¦: {temperature:.4f}")
            self.logger.log_message(f"{'='*60}")

            # 1. é‡ç½®å¥–åŠ±ç³»ç»Ÿ
            self.reward_system.reset_for_generation(generation)

            # 2. å¯¹æŠ—è®­ç»ƒ
            stats = self.adversarial_trainer.train_epoch(
                self.population.individuals,
                generation
            )

            # 2.5 æ›´æ–°å¹³å±€ç‡åˆ°å¥–åŠ±ç³»ç»Ÿï¼ˆç”¨äºè‡ªé€‚åº”å¥–åŠ±åˆ‡æ¢ï¼‰
            draw_rate = stats['draws'] / stats['num_games'] if stats['num_games'] > 0 else 1.0
            self.reward_system.update_draw_rate(draw_rate)
            stats['sparse_enabled'] = self.reward_system.curriculum.sparse_enabled

            # 3. è®°å½•æ—¥å¿—
            self.logger.log_generation(generation, temperature, stats)

            # 4. ä¿å­˜æ£€æŸ¥ç‚¹
            is_best = stats['best_fitness'] > self.best_fitness_ever
            if is_best:
                self.best_fitness_ever = stats['best_fitness']

            if generation % self.config.save_every == 0 or is_best:
                self.checkpoint_manager.save_checkpoint(
                    generation,
                    self.population,
                    temperature,
                    stats,
                    is_best=is_best
                )

            # 5. é—ä¼ æ¼”åŒ–ï¼ˆæœ€åä¸€ä»£ä¸æ¼”åŒ–ï¼‰
            if generation < self.config.num_generations - 1:
                self._evolve_population(temperature)

            # 6. å®šæœŸåŸºå‡†æµ‹è¯•ï¼ˆæ¯10ä»£ï¼‰
            if generation % 10 == 0:
                self._run_benchmark(generation)

        # è®­ç»ƒç»“æŸ
        self.logger.log_message("\n" + "=" * 60)
        self.logger.log_message("è®­ç»ƒå®Œæˆï¼")
        self.logger.log_message(f"æœ€ä½³é€‚åº”åº¦: {self.best_fitness_ever:.2f}")
        self.logger.log_message("=" * 60)
        self.logger.close()

    def _evolve_population(self, temperature: float) -> None:
        """æ‰§è¡Œé—ä¼ æ¼”åŒ–"""
        from genetic_ops import evolve_generation

        self.logger.log_message("å¼€å§‹é—ä¼ æ¼”åŒ–...")

        new_individuals = evolve_generation(
            population=self.population,
            temperature=temperature,
            crossover_alpha=self.config.crossover_alpha,
            mutation_rate=self.config.mutation_rate
        )

        self.population.individuals = new_individuals
        self.logger.log_message("âœ“ é—ä¼ æ¼”åŒ–å®Œæˆ")

    def _run_benchmark(self, generation: int) -> None:
        """è¿è¡ŒåŸºå‡†æµ‹è¯•"""
        try:
            from benchmark import run_benchmark, BenchmarkResult
            from game_interface import TransformerAgent

            self.logger.log_message(f"\n--- åŸºå‡†æµ‹è¯• (Gen {generation}) ---")

            # è·å–æœ€ä¼˜ä¸ªä½“
            self.population.sort_by_fitness()
            best_individual = self.population.individuals[0]

            # åˆ›å»ºTransformeræ™ºèƒ½ä½“
            agent = TransformerAgent(
                team="L",
                model=best_individual.model,
                temperature=0.5  # è¾ƒä½æ¸©åº¦ï¼Œæ›´ç¡®å®šæ€§
            )

            # è¿è¡ŒåŸºå‡†æµ‹è¯•ï¼ˆ20åœºå¿«é€Ÿæµ‹è¯•ï¼‰
            result = run_benchmark(
                transformer_agent=agent,
                num_games=20,
                max_steps=self.config.max_game_steps
            )
            result.generation = generation

            # è®°å½•ç»“æœ
            self.logger.log_message(
                f"åŸºå‡†æµ‹è¯•ç»“æœ: èƒœç‡={result.win_rate:.1%}, "
                f"å¹³å±€ç‡={result.draw_rate:.1%}, "
                f"Lèƒœ={result.left_wins}, Rèƒœ={result.right_wins}"
            )

            # æ£€æŸ¥é˜¶æ®µå‡çº§æ¡ä»¶
            self._check_stage_upgrade(generation, result)

        except Exception as e:
            self.logger.log_message(f"åŸºå‡†æµ‹è¯•å¤±è´¥: {e}")

    def _check_stage_upgrade(self, generation: int, benchmark_result) -> None:
        """æ£€æŸ¥æ˜¯å¦æ»¡è¶³é˜¶æ®µå‡çº§æ¡ä»¶"""
        stage = self.reward_system.curriculum.get_stage(generation)
        win_rate = benchmark_result.win_rate

        if stage == 1 and win_rate >= 0.50:
            self.logger.log_message(f"âœ“ Stage 1å‡çº§æ¡ä»¶æ»¡è¶³: èƒœç‡{win_rate:.1%} >= 50%")
        elif stage == 2 and win_rate >= 0.85:
            self.logger.log_message(f"âœ“ Stage 2å‡çº§æ¡ä»¶æ»¡è¶³: èƒœç‡{win_rate:.1%} >= 85%")
        elif stage == 3 and win_rate >= 0.95:
            self.logger.log_message(f"âœ“ Stage 3å‡çº§æ¡ä»¶æ»¡è¶³: èƒœç‡{win_rate:.1%} >= 95%")

    def _resume_from_checkpoint(self, checkpoint_path: str) -> None:
        """ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ"""
        from population import Population

        checkpoint = self.checkpoint_manager.load_checkpoint(checkpoint_path)

        self.current_generation = checkpoint['generation'] + 1
        self.best_fitness_ever = checkpoint['best_fitness']

        # åŠ è½½ç§ç¾¤
        checkpoint_dir = Path(checkpoint_path)
        population_dir = checkpoint_dir / "population"
        self.population = Population.load_population(
            str(population_dir),
            self.population.config
        )

        self.logger.log_message(f"ä»ä¸–ä»£ {checkpoint['generation']} æ¢å¤è®­ç»ƒ")


# ============================================================
# 4é˜¶æ®µè®­ç»ƒå™¨
# ============================================================

class StagedEvolutionaryTrainer:
    """4é˜¶æ®µè¿›åŒ–è®­ç»ƒå™¨ - æ”¯æŒé˜¶æ®µæ™‹çº§å’ŒHoFå¯¹æ‰‹é‡‡æ ·"""

    def __init__(
        self,
        stage_configs: Dict[TrainingStage, StageConfig],
        experiment_name: str = "staged_training",
        checkpoint_dir: str = "checkpoints",
        log_dir: str = "logs",
        seed: Optional[int] = None
    ):
        """
        Args:
            stage_configs: 4é˜¶æ®µé…ç½®å­—å…¸
            experiment_name: å®éªŒåç§°
            checkpoint_dir: æ£€æŸ¥ç‚¹ç›®å½•
            log_dir: æ—¥å¿—ç›®å½•
            seed: éšæœºç§å­
        """
        self.stage_configs = stage_configs
        self.experiment_name = experiment_name
        self.checkpoint_dir = checkpoint_dir
        self.log_dir = log_dir

        # è®¾ç½®éšæœºç§å­
        if seed is not None:
            self._set_seed(seed)

        # åˆå§‹åŒ–æ—¥å¿—å’Œæ£€æŸ¥ç‚¹ç®¡ç†
        self.logger = TrainingLogger(log_dir, experiment_name)
        self.checkpoint_manager = CheckpointManager(
            checkpoint_dir, keep_best_n=5, experiment_name=experiment_name
        )

        # åˆå§‹åŒ–HoF
        self.hof = HallOfFame(max_size=10)

        # æ¨¡å‹é…ç½®ï¼ˆç”¨äºç§ç¾¤è°ƒæ•´ï¼‰
        from transformer_model import CTFTransformerConfig
        self.model_config = CTFTransformerConfig()

        # å½“å‰çŠ¶æ€
        self.current_stage = TrainingStage.FOUNDATION
        self.current_generation = 0
        self.best_fitness_ever = float('-inf')

        # å»¶è¿Ÿåˆå§‹åŒ–çš„ç»„ä»¶
        self.population = None
        self.reward_system = None
        self.adversarial_trainer = None
        self.annealing = None

    def _set_seed(self, seed: int) -> None:
        """è®¾ç½®éšæœºç§å­"""
        random.seed(seed)
        np.random.seed(seed)
        torch.manual_seed(seed)
        if torch.cuda.is_available():
            torch.cuda.manual_seed_all(seed)

    def _initialize_for_stage(self, stage: TrainingStage) -> None:
        """ä¸ºæŒ‡å®šé˜¶æ®µåˆå§‹åŒ–æˆ–æ›´æ–°ç»„ä»¶"""
        config = self.stage_configs[stage]
        self.current_stage = stage

        self.logger.log_message(f"\n{'='*60}")
        self.logger.log_message(f"åˆå§‹åŒ–é˜¶æ®µ {stage.value}: {config.name}")
        self.logger.log_message(f"{'='*60}")

        # 1. åˆå§‹åŒ–æˆ–è°ƒæ•´ç§ç¾¤
        from population import Population, PopulationConfig

        if self.population is None:
            # é¦–æ¬¡åˆå§‹åŒ–
            pop_config = PopulationConfig(
                population_size=config.population_size,
                elite_size=config.elite_size,
                tournament_size=config.tournament_size
            )
            self.population = Population(pop_config, self.model_config)
            self.logger.log_message(f"ç§ç¾¤å·²åˆ›å»º: {config.population_size} ä¸ªä½“")
        else:
            # è°ƒæ•´ç§ç¾¤å¤§å°
            self.population.resize(config.population_size, self.model_config)
            self.population.config.elite_size = config.elite_size
            self.population.config.tournament_size = config.tournament_size

        # 2. åˆå§‹åŒ–æˆ–æ›´æ–°å¥–åŠ±ç³»ç»Ÿ
        from reward_system import AdaptiveRewardSystem

        if self.reward_system is None:
            self.reward_system = AdaptiveRewardSystem()

        # è®¾ç½®é˜¶æ®µå¥–åŠ±æƒé‡
        self.reward_system.curriculum.set_weights(
            config.dense_weight, config.sparse_weight
        )
        self.logger.log_message(
            f"å¥–åŠ±æƒé‡: dense={config.dense_weight:.1f}, "
            f"sparse={config.sparse_weight:.1f}"
        )

        # 3. åˆ›å»ºå¯¹æŠ—è®­ç»ƒå™¨ï¼ˆæ¯é˜¶æ®µé‡æ–°åˆ›å»ºä»¥æ›´æ–°HoFé‡‡æ ·ç‡ï¼‰
        from adversarial_trainer import AdversarialTrainer, AdaptiveMatchupStrategy

        # é˜¶æ®µè¾¹ç•Œé…ç½®
        stage_boundaries = [
            self.stage_configs[TrainingStage.FOUNDATION].end_gen,
            self.stage_configs[TrainingStage.OPTIMIZATION].end_gen,
            self.stage_configs[TrainingStage.COMPETITION].end_gen
        ]

        matchup_strategy = AdaptiveMatchupStrategy(
            round_robin_until=20,
            tournament_games=config.games_per_individual,
            stage_boundaries=stage_boundaries
        )

        self.adversarial_trainer = AdversarialTrainer(
            matchup_strategy=matchup_strategy,
            reward_system=self.reward_system,
            num_workers=config.num_workers,
            max_steps=1000,
            temperature=1.0,
            hof=self.hof,
            hof_sample_rate=config.hof_sample_rate,
            round_per_game=config.round_per_game
        )
        self.logger.log_message(f"HoFé‡‡æ ·ç‡: {config.hof_sample_rate:.0%}")
        self.logger.log_message(f"å¤šè½®å¯¹æˆ˜: æ¯ä¸ªé…å¯¹ {config.round_per_game} è½®")

        # 4. åˆå§‹åŒ–é€€ç«è°ƒåº¦å™¨
        from genetic_ops import AnnealingScheduler, AnnealingConfig

        annealing_config = AnnealingConfig(
            initial_temperature=config.initial_temperature,
            min_temperature=config.min_temperature,
            cooling_rate=config.cooling_rate
        )
        self.annealing = AnnealingScheduler(annealing_config)

        self.logger.log_message(f"é˜¶æ®µ {stage.value} åˆå§‹åŒ–å®Œæˆ")

    def train(self) -> None:
        """æ‰§è¡Œ4é˜¶æ®µè®­ç»ƒæµç¨‹"""
        self.logger.log_message("=" * 60)
        self.logger.log_message("å¼€å§‹4é˜¶æ®µè¿›åŒ–è®­ç»ƒ")
        self.logger.log_message("=" * 60)

        # éå†4ä¸ªé˜¶æ®µ
        for stage in TrainingStage:
            config = self.stage_configs[stage]

            self.logger.log_message(f"\n{'#'*60}")
            self.logger.log_message(f"# é˜¶æ®µ {stage.value}: {config.name}")
            self.logger.log_message(f"# ä¸–ä»£èŒƒå›´: {config.start_gen} - {config.end_gen}")
            self.logger.log_message(f"# ç§ç¾¤å¤§å°: {config.population_size}")
            self.logger.log_message(f"{'#'*60}")

            # åˆå§‹åŒ–é˜¶æ®µ
            self._initialize_for_stage(stage)

            # è®­ç»ƒå½“å‰é˜¶æ®µ
            advanced = self._train_stage(stage)

            if advanced:
                # ä¿å­˜å† å†›åˆ°HoF
                self._save_champion_to_hof(stage)
                self.logger.log_message(f"âœ“ é˜¶æ®µ {stage.value} å®Œæˆï¼Œæ™‹çº§åˆ°ä¸‹ä¸€é˜¶æ®µ")
            else:
                self.logger.log_message(f"âœ— é˜¶æ®µ {stage.value} æœªèƒ½æ™‹çº§ï¼Œè®­ç»ƒç»“æŸ")
                break

        # è®­ç»ƒç»“æŸ
        self.logger.log_message("\n" + "=" * 60)
        self.logger.log_message("4é˜¶æ®µè®­ç»ƒå®Œæˆï¼")
        self.logger.log_message(f"æœ€ä½³é€‚åº”åº¦: {self.best_fitness_ever:.2f}")
        self.logger.log_message(f"HoFæˆå‘˜æ•°: {len(self.hof)}")
        self.logger.log_message("=" * 60)

        # ä¿å­˜HoF
        hof_path = Path(self.log_dir) / self.experiment_name / "hof"
        self.hof.save(str(hof_path))

        self.logger.close()

    def _train_stage(self, stage: TrainingStage) -> bool:
        """
        è®­ç»ƒå•ä¸ªé˜¶æ®µ

        ä¿®å¤: ä½¿ç”¨ max_generations ä½œä¸ºå¾ªç¯ä¸Šé™ï¼Œè€Œé end_gen

        Args:
            stage: å½“å‰é˜¶æ®µ

        Returns:
            æ˜¯å¦æˆåŠŸæ™‹çº§
        """
        config = self.stage_configs[stage]
        stage_start_gen = config.start_gen

        # ä½¿ç”¨ max_generations ä½œä¸ºå¾ªç¯ä¸Šé™ï¼ˆä¿®å¤åŸ bugï¼‰
        for generations_in_stage in range(1, config.max_generations + 1):
            gen = stage_start_gen + generations_in_stage - 1
            self.current_generation = gen

            # è·å–æ¸©åº¦ï¼ˆç›¸å¯¹äºé˜¶æ®µå†…çš„ä¸–ä»£æ•°ï¼‰
            temperature = self.annealing.get_temperature(generations_in_stage - 1)

            self.logger.log_message(f"\n--- ä¸–ä»£ {gen} (é˜¶æ®µå†…ç¬¬{generations_in_stage}ä»£) ---")

            # 1. é‡ç½®å¥–åŠ±ç³»ç»Ÿ
            self.reward_system.reset_for_generation(gen)

            # 2. å¯¹æŠ—è®­ç»ƒ
            stats = self.adversarial_trainer.train_epoch(
                self.population.individuals, gen
            )

            # 3. æ›´æ–°å¹³å±€ç‡
            draw_rate = stats['draws'] / stats['num_games'] if stats['num_games'] > 0 else 1.0
            self.reward_system.update_draw_rate(draw_rate)

            # 4. è®°å½•æ—¥å¿—
            self.logger.log_generation(gen, temperature, stats)

            # 5. æ›´æ–°æœ€ä½³é€‚åº”åº¦
            if stats['best_fitness'] > self.best_fitness_ever:
                self.best_fitness_ever = stats['best_fitness']

            # 6. ä¿å­˜æ£€æŸ¥ç‚¹
            if generations_in_stage % config.benchmark_interval == 0:
                self.checkpoint_manager.save_checkpoint(
                    gen, self.population, temperature, stats,
                    is_best=(stats['best_fitness'] == self.best_fitness_ever)
                )

            # 7. æ£€æŸ¥æ™‹çº§æ¡ä»¶ï¼ˆè¾¾åˆ°æœ€å°ä¸–ä»£æ•°åï¼‰
            if generations_in_stage >= config.min_generations:
                if generations_in_stage % config.benchmark_interval == 0:
                    advanced = self._check_advancement(stage, gen)
                    if advanced:
                        return True

            # 8. é—ä¼ æ¼”åŒ–
            self._evolve_population(temperature)

        # è¾¾åˆ°æœ€å¤§ä¸–ä»£æ•°ï¼Œå¼ºåˆ¶ç»“æŸé˜¶æ®µ
        self.logger.log_message(
            f"è¾¾åˆ°æœ€å¤§ä¸–ä»£æ•° {config.max_generations}ï¼Œå¼ºåˆ¶ç»“æŸé˜¶æ®µ"
        )
        return config.auto_advance

    def _check_advancement(self, stage: TrainingStage, generation: int) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦æ»¡è¶³æ™‹çº§æ¡ä»¶

        Args:
            stage: å½“å‰é˜¶æ®µ
            generation: å½“å‰ä¸–ä»£

        Returns:
            æ˜¯å¦å¯ä»¥æ™‹çº§
        """
        config = self.stage_configs[stage]

        # è‡ªåŠ¨æ™‹çº§æ¨¡å¼ï¼ˆå¿«é€Ÿæµ‹è¯•ï¼‰
        if config.auto_advance:
            self.logger.log_message("è‡ªåŠ¨æ™‹çº§æ¨¡å¼ï¼Œè·³è¿‡èƒœç‡æ£€æŸ¥")
            return True

        self.logger.log_message(f"\n--- åŸºå‡†æµ‹è¯• (Gen {generation}) ---")

        try:
            from benchmark import run_benchmark
            from game_interface import TransformerAgent

            # è·å–æœ€ä¼˜ä¸ªä½“
            self.population.sort_by_fitness()
            best_individual = self.population.individuals[0]

            # åˆ›å»ºæ™ºèƒ½ä½“
            agent = TransformerAgent(
                team="L",
                model=best_individual.model,
                temperature=0.5
            )

            # è¿è¡ŒåŸºå‡†æµ‹è¯•
            result = run_benchmark(
                transformer_agent=agent,
                num_games=config.min_benchmark_games,
                max_steps=1000
            )

            # è®¡ç®—ç½®ä¿¡åŒºé—´
            win_rate, lower, upper = calculate_win_rate_with_ci(
                result.left_wins, result.total_games
            )

            self.logger.log_message(
                f"åŸºå‡†æµ‹è¯•: èƒœç‡={win_rate:.1%} "
                f"(95% CI: [{lower:.1%}, {upper:.1%}]), "
                f"é—¨æ§›={config.min_win_rate:.0%}"
            )

            # æ£€æŸ¥ä¸‹ç•Œæ˜¯å¦è¾¾æ ‡
            if lower >= config.min_win_rate:
                self.logger.log_message(
                    f"âœ“ æ™‹çº§æ¡ä»¶æ»¡è¶³: ä¸‹ç•Œ{lower:.1%} >= {config.min_win_rate:.0%}"
                )
                return True
            else:
                self.logger.log_message(
                    f"âœ— æ™‹çº§æ¡ä»¶æœªæ»¡è¶³: ä¸‹ç•Œ{lower:.1%} < {config.min_win_rate:.0%}"
                )
                return False

        except Exception as e:
            self.logger.log_message(f"åŸºå‡†æµ‹è¯•å¤±è´¥: {e}")
            return False

    def _save_champion_to_hof(self, stage: TrainingStage) -> None:
        """ä¿å­˜å½“å‰é˜¶æ®µå† å†›åˆ°HoF"""
        self.population.sort_by_fitness()
        best = self.population.individuals[0]

        # è®¡ç®—èƒœç‡
        win_rate = best.win_rate() if best.games_played > 0 else 0.0

        # ä¿å­˜åˆ°HoF
        self.hof.add_champion(
            model_state_dict=best.model.state_dict(),
            stage=stage.value,
            generation=self.current_generation,
            win_rate=win_rate,
            metadata={
                'fitness': best.fitness,
                'wins': best.wins,
                'losses': best.losses,
                'flags_captured': best.flags_captured
            }
        )

        self.logger.log_message(
            f"å† å†›å·²ä¿å­˜åˆ°HoF: Stage {stage.value}, "
            f"Gen {self.current_generation}, WR {win_rate:.1%}"
        )

    def _evolve_population(self, temperature: float) -> None:
        """æ‰§è¡Œé—ä¼ æ¼”åŒ–"""
        from genetic_ops import evolve_generation

        config = self.stage_configs[self.current_stage]

        new_individuals = evolve_generation(
            population=self.population,
            temperature=temperature,
            crossover_alpha=config.crossover_alpha,
            mutation_rate=config.mutation_rate
        )

        self.population.individuals = new_individuals


# ============================================================
# å‘½ä»¤è¡Œæ¥å£
# ============================================================

import argparse


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="CTF Transformer è¿›åŒ–è®­ç»ƒ"
    )

    # é…ç½®æ–‡ä»¶
    parser.add_argument(
        '--config',
        type=str,
        default=None,
        help='é…ç½®æ–‡ä»¶è·¯å¾„ (JSONæ ¼å¼)'
    )

    # æ¢å¤è®­ç»ƒ
    parser.add_argument(
        '--resume',
        type=str,
        default=None,
        help='æ£€æŸ¥ç‚¹è·¯å¾„ï¼ˆæ¢å¤è®­ç»ƒï¼‰'
    )

    # å¿«é€Ÿæµ‹è¯•æ¨¡å¼
    parser.add_argument(
        '--quick-test',
        action='store_true',
        help='å¿«é€Ÿæµ‹è¯•æ¨¡å¼ï¼ˆå°è§„æ¨¡è®­ç»ƒï¼‰'
    )

    # 4é˜¶æ®µå¿«é€Ÿæµ‹è¯•æ¨¡å¼
    parser.add_argument(
        '--quick-test-staged',
        action='store_true',
        help='4é˜¶æ®µå¿«é€Ÿæµ‹è¯•æ¨¡å¼ï¼ˆå®Œæ•´æµç¨‹éªŒè¯ï¼Œçº¦5åˆ†é’Ÿï¼‰'
    )

    # 4é˜¶æ®µå®Œæ•´è®­ç»ƒæ¨¡å¼
    parser.add_argument(
        '--staged',
        action='store_true',
        help='4é˜¶æ®µå®Œæ•´è®­ç»ƒæ¨¡å¼'
    )

    # è¦†ç›–é…ç½®å‚æ•°
    parser.add_argument('--population-size', type=int, help='ç§ç¾¤å¤§å°')
    parser.add_argument('--num-generations', type=int, help='ä¸–ä»£æ•°')
    parser.add_argument('--num-workers', type=int, help='å¹¶è¡Œå·¥ä½œè¿›ç¨‹æ•°')
    parser.add_argument('--seed', type=int, help='éšæœºç§å­')
    parser.add_argument('--experiment-name', type=str, help='å®éªŒåç§°')

    return parser.parse_args()


def main():
    """ä¸»å‡½æ•°"""
    args = parse_arguments()

    # 4é˜¶æ®µå¿«é€Ÿæµ‹è¯•æ¨¡å¼
    if args.quick_test_staged:
        print("âš¡ 4é˜¶æ®µå¿«é€Ÿæµ‹è¯•æ¨¡å¼")
        stage_configs = create_quick_test_configs()
        trainer = StagedEvolutionaryTrainer(
            stage_configs=stage_configs,
            experiment_name="quick_test_staged",
            seed=args.seed
        )
        try:
            trainer.train()
        except KeyboardInterrupt:
            print("\nè®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
            trainer.logger.close()
        except Exception as e:
            print(f"\nè®­ç»ƒå‡ºé”™: {e}")
            trainer.logger.close()
            raise
        return

    # 4é˜¶æ®µå®Œæ•´è®­ç»ƒæ¨¡å¼
    if args.staged:
        print("ğŸš€ 4é˜¶æ®µå®Œæ•´è®­ç»ƒæ¨¡å¼")
        stage_configs = create_stage_configs()
        experiment_name = args.experiment_name or "staged_training"
        trainer = StagedEvolutionaryTrainer(
            stage_configs=stage_configs,
            experiment_name=experiment_name,
            seed=args.seed
        )
        try:
            trainer.train()
        except KeyboardInterrupt:
            print("\nè®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
            trainer.logger.close()
        except Exception as e:
            print(f"\nè®­ç»ƒå‡ºé”™: {e}")
            trainer.logger.close()
            raise
        return

    # åŸæœ‰è®­ç»ƒæ¨¡å¼ï¼ˆå‘åå…¼å®¹ï¼‰
    if args.config:
        config = load_config(args.config)
    else:
        config = TrainingConfig()

    # å¿«é€Ÿæµ‹è¯•æ¨¡å¼
    if args.quick_test:
        config.population_size = 4
        config.num_generations = 5
        config.max_game_steps = 100
        config.num_workers = 2
        config.experiment_name = "quick_test"
        print("âš¡ å¿«é€Ÿæµ‹è¯•æ¨¡å¼")

    # è¦†ç›–é…ç½®å‚æ•°
    if args.population_size:
        config.population_size = args.population_size
    if args.num_generations:
        config.num_generations = args.num_generations
    if args.num_workers:
        config.num_workers = args.num_workers
    if args.seed:
        config.seed = args.seed
    if args.experiment_name:
        config.experiment_name = args.experiment_name

    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = EvolutionaryTrainer(config)

    # å¼€å§‹è®­ç»ƒ
    try:
        trainer.train(resume_from=args.resume)
    except KeyboardInterrupt:
        print("\nè®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        trainer.logger.log_message("è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        trainer.logger.close()
    except Exception as e:
        print(f"\nè®­ç»ƒå‡ºé”™: {e}")
        trainer.logger.log_message(f"è®­ç»ƒå‡ºé”™: {e}")
        trainer.logger.close()
        raise


if __name__ == "__main__":
    main()

